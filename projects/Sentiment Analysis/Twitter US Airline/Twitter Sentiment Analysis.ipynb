{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Packages for data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Packages for modeling\n",
    "from keras import models\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\utkarsh.goyal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11693</th>\n",
       "      <td>@USAirways @AmericanAir Your staff members are...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>@united Trying to locate passenger that landed...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7862</th>\n",
       "      <td>@JetBlue if you want to fly in a storm that's ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>@JetBlue If this is customer service, then ple...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>@united I'm Cancelled Flighting my #mileageplu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "11693  @USAirways @AmericanAir Your staff members are...          negative\n",
       "3478   @united Trying to locate passenger that landed...           neutral\n",
       "7862   @JetBlue if you want to fly in a storm that's ...          negative\n",
       "7745   @JetBlue If this is customer service, then ple...          negative\n",
       "2685   @united I'm Cancelled Flighting my #mileageplu...          negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Tweets.csv')\n",
    "df = df.reindex(np.random.permutation(df.index))  \n",
    "df = df[['text', 'airline_sentiment']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(input_text):\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "        whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "        return \" \".join(clean_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11693</th>\n",
       "      <td>@USAirways @AmericanAir Your staff members loo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>@united Trying locate passenger landed hrs ago...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7862</th>\n",
       "      <td>@JetBlue want fly storm that's right. But give...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>@JetBlue If customer service, please call me.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>@united I'm Cancelled Flighting #mileageplus c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "11693  @USAirways @AmericanAir Your staff members loo...          negative\n",
       "3478   @united Trying locate passenger landed hrs ago...           neutral\n",
       "7862   @JetBlue want fly storm that's right. But give...          negative\n",
       "7745       @JetBlue If customer service, please call me.          negative\n",
       "2685   @united I'm Cancelled Flighting #mileageplus c...          negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text = df.text.apply(remove_stopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11693</th>\n",
       "      <td>Your staff members looking like two heads. C...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>Trying locate passenger landed hrs ago  UA938...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7862</th>\n",
       "      <td>want fly storm that's right. But give us choi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>If customer service, please call me.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>I'm Cancelled Flighting #mileageplus card NEV...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "11693    Your staff members looking like two heads. C...          negative\n",
       "3478    Trying locate passenger landed hrs ago  UA938...           neutral\n",
       "7862    want fly storm that's right. But give us choi...          negative\n",
       "7745                If customer service, please call me.          negative\n",
       "2685    I'm Cancelled Flighting #mileageplus card NEV...          negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_mentions(input_text):\n",
    "        return re.sub(r'@\\w+', '', input_text)\n",
    "    \n",
    "df.text = df.text.apply(remove_mentions)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train data samples: 10980\n",
      "# Test data samples: 3660\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.text, df.airline_sentiment, test_size=0.25, random_state=7)\n",
    "print('# Train data samples:', X_train.shape[0])\n",
    "print('# Test data samples:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted tokenizer on 10980 documents\n",
      "25000 words in dictionary\n",
      "Top 5 most common words are: [('flight', 2998), ('not', 1202), ('no', 1128), ('get', 1013), ('t', 887)]\n"
     ]
    }
   ],
   "source": [
    "tk = Tokenizer(num_words=25000,\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \")\n",
    "\n",
    "tk.fit_on_texts(X_train)\n",
    "\n",
    "print('Fitted tokenizer on {} documents'.format(tk.document_count))\n",
    "print('{} words in dictionary'.format(tk.num_words))\n",
    "print('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" What  said.\" is converted into [30, 322, 5453, 5454, 302, 323, 423, 669, 480, 164, 53, 1474, 1376]\n"
     ]
    }
   ],
   "source": [
    "X_train_seq = tk.texts_to_sequences(X_train)\n",
    "X_test_seq = tk.texts_to_sequences(X_test)\n",
    "\n",
    "print('\"{}\" is converted into {}'.format(X_train[0], X_train_seq[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"[30, 322, 5453, 5454, 302, 323, 423, 669, 480, 164, 53, 1474, 1376]\" is converted into [0. 0. 0. ... 0. 0. 0.]\n",
      "For this example we have 13.0 features with a value of 1.\n"
     ]
    }
   ],
   "source": [
    "def one_hot_seq(seqs, nb_features = 25000):\n",
    "    ohs = np.zeros((len(seqs), nb_features))\n",
    "    for i, s in enumerate(seqs):\n",
    "        ohs[i, s] = 1.\n",
    "    return ohs\n",
    "\n",
    "X_train_oh = one_hot_seq(X_train_seq)\n",
    "X_test_oh = one_hot_seq(X_test_seq)\n",
    "\n",
    "print('\"{}\" is converted into {}'.format(X_train_seq[0], X_train_oh[0]))\n",
    "print('For this example we have {} features with a value of 1.'.format(X_train_oh[0].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"neutral\" is converted into 2\n",
      "\"2\" is converted into [0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.transform(y_test)\n",
    "y_train_oh = to_categorical(y_train_le)\n",
    "y_test_oh = to_categorical(y_test_le)\n",
    "\n",
    "print('\"{}\" is converted into {}'.format(y_train[0], y_train_le[0]))\n",
    "print('\"{}\" is converted into {}'.format(y_train_le[0], y_train_oh[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ocL_c0eIyuSv"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Inh-l6Xby3FO"
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "#     'svm': {\n",
    "#         'model': SVC(gamma='auto',max_iter=-1),\n",
    "#         'params' : {\n",
    "#             'C': [1,10,20],\n",
    "#             # 'kernel': ['linear', 'rbf',],\n",
    "#     #         #'shrinking':['True', 'False']\n",
    "#         }  \n",
    "#     },\n",
    "\n",
    "#     'kneighbours': {\n",
    "#         'model': KNeighborsClassifier(n_jobs=-1),\n",
    "#         \"params\": {\n",
    "            \n",
    "#             'n_neighbors' : [5, 10, 20, 30],\n",
    "#         }\n",
    "#     },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(n_jobs=-1),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10,100],\n",
    "            'max_depth': [1,2,3,4,5,6],\n",
    "            'min_samples_leaf': [100,200,300,500,1000],\n",
    "            'criterion' : ['gini','entropy'], \n",
    "        }\n",
    "    },\n",
    "#     'logistic_regression' : {\n",
    "#         'model': LogisticRegression(multi_class='auto'),\n",
    "#         'params': {\n",
    "#             'C': [1,5,10],\n",
    "# #             'solver':['newton-cg', 'liblinear']\n",
    "#         }\n",
    "#     },\n",
    "#     'naive_bayes_gaussian': {\n",
    "#         'model': GaussianNB(),\n",
    "#         'params': {}\n",
    "#     },\n",
    "#     'naive_bayes_multinomial': {\n",
    "#         'model': MultinomialNB(),\n",
    "#         'params': {}\n",
    "#     },\n",
    "#     'decision_tree': {\n",
    "#         'model': DecisionTreeClassifier(),\n",
    "#         'params': {\n",
    "#             'criterion': ['gini','entropy'],\n",
    "#             'max_depth': [1,2,3,4,5,6],\n",
    "#             'min_samples_leaf': [100,200,300,500,1000]\n",
    "#         }\n",
    "#     }     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "-5FqBmTey5LV",
    "outputId": "004dc6db-71bd-4b2a-d36c-0377b4af42bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    print(model_name)\n",
    "    clf =  GridSearchCV(mp['model'], mp['params'], cv=2, \n",
    "                        return_train_score=False)\n",
    "    clf.fit(X_train_oh, y_train_oh)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "score_df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling-Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Sequential()\n",
    "base_model.add(Dense(64, activation='relu', input_shape=(25000,)))\n",
    "base_model.add(Dropout(0.5))\n",
    "base_model.add(Dense(32, activation='relu'))\n",
    "base_model.add(Dropout(0.5))\n",
    "base_model.add(Dense(3, activation='softmax'))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(optimizer='rmsprop'\n",
    "                  , loss='categorical_crossentropy'\n",
    "                  , metrics=['accuracy'])\n",
    "    \n",
    "base_model.fit(X_train_oh, y_train_oh, epochs=50, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.evaluate(X_test_oh, y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
